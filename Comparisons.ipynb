{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from math import isnan\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, precision_recall_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "1be1b712b5581d48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "df_path = 'Datasets/'\n",
    "users = pd.read_csv(df_path + 'v2_top10_embeddings_users.csv')\n",
    "emb = np.load(df_path + 'v2_top10_embeddings.npy')\n",
    "df2 = pd.concat([users, pd.DataFrame(emb)], axis=1)\n",
    "\n",
    "print(f\"Data shape: {df2.shape}\")\n",
    "print(f\"Label distribution:\\n{df2['label'].value_counts()}\")\n",
    "#df2 = df2.drop(columns=[i for i in range(768)])\n",
    "df2.head()"
   ],
   "id": "2e04bc27bb30da2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#load features\n",
    "features = pd.read_csv(df_path + 'df_preprocessed.csv')\n",
    "print(f\"Data shape: {features.shape}\")\n",
    "print(f\"Label distribution:\\n{features['label'].value_counts()}\")\n",
    "features.head()"
   ],
   "id": "bfd6f881cde6c060",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "desc = np.load(df_path + 'description_embeddings.npy')\n",
    "print(desc.shape)\n",
    "desc_merged = pd.concat([features, pd.DataFrame(desc)], axis=1)"
   ],
   "id": "3e392088e9a35800",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "desc_merged.rename(columns=lambda c: f\"D{c}\" if str(c).isdigit() else c, inplace=True)\n",
    "desc_merged.head()"
   ],
   "id": "65ab32113d26ff64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df2['has_embedding'] = 1\n",
    "df2.rename(columns=lambda c: f\"T{c}\" if str(c).isdigit() else c, inplace=True)\n",
    "df2_merged = desc_merged.merge(df2, left_on=\"id\", right_on='author_id',how=\"left\")\n",
    "df2_merged = df2_merged.fillna(0)\n",
    "df2_merged.shape"
   ],
   "id": "af0ef78b07bf9831",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df2_merged.head()",
   "id": "64dd154a151df7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "df_path = 'Datasets/'\n",
    "users = pd.read_csv(df_path + 'v2_top10_embeddings_users.csv')\n",
    "emb = np.load(df_path + 'v2_top10_embeddings.npy')\n",
    "df2 = pd.concat([users, pd.DataFrame(emb)], axis=1)\n",
    "\n",
    "print(f\"Data shape: {df2.shape}\")\n",
    "print(f\"Label distribution:\\n{df2['label'].value_counts()}\")\n",
    "#load features\n",
    "features = pd.read_csv(df_path + 'df_preprocessed.csv')\n",
    "print(f\"Data shape: {features.shape}\")\n",
    "print(f\"Label distribution:\\n{features['label'].value_counts()}\")\n",
    "desc = np.load(df_path + 'description_embeddings.npy')\n",
    "print(desc.shape)\n",
    "desc_merged = pd.concat([features, pd.DataFrame(desc)], axis=1)\n",
    "desc_merged.rename(columns=lambda c: f\"D{c}\" if str(c).isdigit() else c, inplace=True)\n",
    "df2['has_embedding'] = 1\n",
    "df2.rename(columns=lambda c: f\"T{c}\" if str(c).isdigit() else c, inplace=True)\n",
    "df2_merged = desc_merged.merge(df2, left_on=\"id\", right_on='author_id',how=\"left\")\n",
    "df2_merged = df2_merged.fillna(0)\n",
    "df2_merged.shape"
   ],
   "id": "112f96d0b1f0f591",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "def prepare_data(df):\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    #print(f\"Class distribution:\\n{df['label'].value_counts()}\")\n",
    "\n",
    "    # Get feature columns (the numeric columns 0-383)\n",
    "    #feature_cols = [i for i in range(df.shape[1]-50)]\n",
    "    cols_to_remove = ['created_at', 'description', 'entities', 'id', 'location', 'name', 'pinned_tweet_id', 'profile_image_url', 'protected', 'public_metrics', 'url', 'username', 'verified', 'account_age_days', 'author_id', 'label_y', 'split_y', 'withheld', 'n_tweets']\n",
    "    df = df.drop(columns=cols_to_remove)\n",
    "    df = df.rename(columns={'label_x': 'label', 'split_x':'split'})\n",
    "\n",
    "    #X_emb = df[feature_cols]\n",
    "    #X_features = df[df.columns.difference(cols_to_remove+feature_cols)]\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df['label'])\n",
    "    print(df['label'][0], y[0])\n",
    "\n",
    "    # Split using existing split column\n",
    "    \"\"\"X_train_emb = X_emb[df['split'] == 'train']\n",
    "    X_train_features = X_features[df['split'] == 'train']\n",
    "    X_train_features = X_train_features.drop(columns=['label', 'split'])\"\"\"\n",
    "    X_train = df[df['split'] == 'train']\n",
    "    X_train = X_train.drop(columns=['label', 'split'])\n",
    "    y_train = y[df['split'] == 'train']\n",
    "    \"\"\"X_val_emb = X_emb[df['split'] == 'val']\n",
    "    X_val_features = X_features[df['split'] == 'val']\n",
    "    X_val_features = X_val_features.drop(columns=['label', 'split'])\"\"\"\n",
    "    X_val = df[df['split'] == 'val']\n",
    "    X_val = X_val.drop(columns=['label', 'split'])\n",
    "    y_val = y[df['split'] == 'val']\n",
    "    \"\"\"X_test_emb = X_emb[df['split'] == 'test']\n",
    "    X_test_features = X_features[df['split'] == 'test']\n",
    "    X_test_features = X_test_features.drop(columns=['label', 'split'])\"\"\"\n",
    "    X_test = df[df['split'] == 'test']\n",
    "    X_test = X_test.drop(columns=['label', 'split'])\n",
    "    y_test = y[df['split'] == 'test']\n",
    "\n",
    "    print(f\"\\nSplit sizes - Train: {len(y_train)}, Val: {len(y_val)}, Test: {len(y_test)}\")\n",
    "    print(f\"Train class distribution: {pd.Series(y_train).value_counts().to_dict()}\")\n",
    "    print(f\"Validation class distribution: {pd.Series(y_val).value_counts().to_dict()}\")\n",
    "    print(f\"Test class distribution: {pd.Series(y_test).value_counts().to_dict()}\")\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, le"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'aucpr',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1, 20),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1.0),\n",
    "        #'col_sample_bylevel': trial.suggest_float('col_sample_bylevel', 0.3, 1.0),\n",
    "        #'col_sample_bynode': trial.suggest_float('col_sample_bynode', 0.3, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 10.0),\n",
    "        'alpha': trial.suggest_float('reg_alpha', 1e-4, 1.0, log=True),\n",
    "        'lambda': trial.suggest_float('reg_lambda', 0.1, 20.0, log=True),\n",
    "        'max_delta_step': trial.suggest_float('max_delta_step', 0.0, 5.0),\n",
    "        'tree_method': 'hist',\n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dval, 'val')],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    y_pred = (model.predict(dval) >= 0.5).astype(int)\n",
    "\n",
    "    \"\"\"precision_neg = precision_score(y_val, y_pred, pos_label=0)\n",
    "    recall_pos = recall_score(y_val, y_pred, pos_label=1)\n",
    "\n",
    "    score = 2 * precision_neg * recall_pos / (precision_neg + recall_pos + 1e-9)\"\"\"\n",
    "    f1 = f1_score(y_val, y_pred, pos_label=0)\n",
    "    return f1\n"
   ],
   "id": "47201538d3ab5f69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train, y_train, X_val, y_val, X_test, y_test, le = prepare_data(df2_merged)",
   "id": "e123aeffd62aeb2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#X_train = pd.concat([X_train_emb, X_train_features], axis=1)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "#X_val = pd.concat([X_val_emb, X_val_features], axis=1)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "#X_test = pd.concat([X_test_emb, X_test_features], axis=1)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ],
   "id": "a6459efa7e8d5c34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_pos = np.sum(y_train==1)\n",
    "n_neg = np.sum(y_train==0)\n",
    "scale_pos_weight = n_neg / n_pos\n",
    "print(f\"Scale pos weight: {scale_pos_weight:.2f}\")"
   ],
   "id": "db9a5ced790202ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'aucpr',\n",
    "    'learning_rate': 0.05,\n",
    "    'scale_pos_weight': scale_pos_weight,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "    num_boost_round=1000,\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=50,\n",
    ")"
   ],
   "id": "1c4d9a1b3554aee6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_val_pred = (model.predict(dval) >= 0.5).astype(int)\n",
    "print(classification_report(y_val, y_val_pred, target_names=['bot', 'human']))"
   ],
   "id": "85853524378c6e24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xgb.plot_importance(model, max_num_features=20)\n",
    "plt.show()"
   ],
   "id": "fb0a3c73ab19a0ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)\n",
    "print(\"Best custom F1:\", study.best_trial.value)"
   ],
   "id": "d7ecd6c35df6374a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get best params\n",
    "best_params = study.best_trial.params\n",
    "print(\"Best parameters:\", best_params)"
   ],
   "id": "621f3eecf4044de4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Retrain model with best params\n",
    "best_params.update({\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'aucpr',\n",
    "    #'scale_pos_weight': scale_pos_weight,\n",
    "    'seed': 42\n",
    "})\n",
    "best_model = xgb.train(\n",
    "    best_params,\n",
    "    dtrain,\n",
    "    evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "    num_boost_round=1000,\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=50,\n",
    ")"
   ],
   "id": "c69917f68b143fb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xgb.plot_importance(best_model, max_num_features=20)\n",
    "plt.show()"
   ],
   "id": "6a4ed83cb9082263",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Predictions\n",
    "y_test_pred = (best_model.predict(dtest) >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred, target_names=['bot', 'human']))"
   ],
   "id": "95b3fd9b09a9e2d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_val_proba = best_model.predict(dval)\n",
    "y_val_proba"
   ],
   "id": "c13c52ff3dbea9c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_val, y_val_proba)\n",
    "precision.shape, recall.shape, thresholds.shape"
   ],
   "id": "39b5a5d77a0f9eb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"valid = precision[:-1] >= 0.76\n",
    "valid_recalls = recall[:-1][valid]\n",
    "valid_thresholds = thresholds[valid]\n",
    "\n",
    "best_idx = np.argmax(valid_recalls)\n",
    "best_threshold = valid_thresholds[best_idx]\"\"\"\n",
    "\n",
    "f1=2*precision*recall/(precision+recall+1e-9)\n",
    "best_threshold = thresholds[np.argmax(f1)]\n",
    "\n",
    "print(best_threshold)"
   ],
   "id": "e5024bd9a4b8ac28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_val_proba = best_model.predict(dval)\n",
    "y_val_pred = (y_val_proba >= best_threshold).astype(int)\n",
    "print(classification_report(y_val, y_val_pred, target_names=['bot', 'human']))"
   ],
   "id": "5bbef13b7aa59176",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_test_proba = best_model.predict(dtest)\n",
    "y_test_pred = (y_test_proba >= best_threshold).astype(int)\n",
    "print(classification_report(y_test, y_test_pred, target_names=['bot', 'human']))"
   ],
   "id": "61aafafeac82fed4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f7603e6b590e41fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5b12390bbdec59d4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
